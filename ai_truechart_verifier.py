# ==========================================================
# LynkerAI TrueChart Verifier v3.2
# AIè®°å¿†æ•°æ®åº“ç‰ˆï¼ˆSupabase å†™å…¥æœºåˆ¶ï¼‰
# ==========================================================

import json, os, re
from datetime import datetime
from sentence_transformers import SentenceTransformer, util
from supabase_init import init_supabase

# ----------------------------------------------------------
# åŠ è½½æ¨¡å‹
# ----------------------------------------------------------
print("ğŸ§  Loading high-semantic Chinese model (shibing624/text2vec-base-chinese)...")
model = SentenceTransformer("shibing624/text2vec-base-chinese")
print("âœ… Model loaded successfully!")

# ----------------------------------------------------------
# åˆå§‹åŒ– Supabase å®¢æˆ·ç«¯
# ----------------------------------------------------------
supabase = init_supabase()

# ----------------------------------------------------------
# è¾…åŠ©å‡½æ•°
# ----------------------------------------------------------
def semantic_similarity(a: str, b: str) -> float:
    emb1 = model.encode(a, convert_to_tensor=True)
    emb2 = model.encode(b, convert_to_tensor=True)
    return round(float(util.pytorch_cos_sim(emb1, emb2).item()), 4)

def extract_features_from_chart(chart_text: str):
    patterns = {
        "æ¯ç¼˜æµ…": r"(æ¯|æ¯äº²|å¥³æ€§é•¿è¾ˆ).{0,4}(äº¡|å»ä¸–|ç¼˜è–„|ä¸åˆ©)",
        "å©šè¿Ÿ": r"(å©š|é…å¶|å¤«å¦»).{0,4}(æ™š|è¿Ÿ|éš¾|ç ´)",
        "äº‹ä¸šæ³¢æŠ˜": r"(äº‹|ä¸š|å·¥ä½œ|å®˜ç¦„).{0,4}(æ³¢æŠ˜|å¤šå˜|èµ·ä¼|ç ´)",
        "è´¢è¿å¥½": r"(è´¢|é’±|æ”¶å…¥).{0,4}(æ—º|ä½³|å¥½|ç¨³)",
        "å¥åº·å¼±": r"(ç–¾|ç—…|èº«|å¥åº·).{0,4}(å¼±|ä¸ä½³|å—æŸ)",
    }
    features = [k for k, p in patterns.items() if re.search(p, chart_text)]
    raw_terms = re.findall(r"[\u4e00-\u9fa5]{2,6}", chart_text)
    features.extend(list(set(raw_terms[:50])))
    return list(set(features))

# ----------------------------------------------------------
# æ™ºèƒ½æƒé‡å­¦ä¹ ç³»ç»Ÿ
# ----------------------------------------------------------
def update_event_weights(supabase_client, unmatched_events):
    """åŠ¨æ€è°ƒæ•´äººç”Ÿäº‹ä»¶æƒé‡ï¼ŒåŸºäºç›¸ä¼¼åº¦è¿›è¡Œæ™ºèƒ½å­¦ä¹ """
    if supabase_client is None:
        return
    
    for e in unmatched_events:
        new_weight = e["weight"]
        sim = e["similarity"]
        
        # æ™ºèƒ½æƒé‡è°ƒæ•´ç­–ç•¥
        if sim > 0.6:
            # ç›¸ä¼¼åº¦é«˜ä½†æœªåŒ¹é…ï¼Œå¢åŠ æƒé‡
            new_weight = min(e["weight"] + 0.1, 3.0)
        elif sim < 0.3:
            # ç›¸ä¼¼åº¦æä½ï¼Œé™ä½æƒé‡
            new_weight = max(e["weight"] - 0.05, 0.5)
        
        e["weight"] = new_weight
        
        try:
            supabase_client.table("life_event_weights").upsert({
                "event_desc": e["desc"],
                "weight": new_weight,
                "similarity": sim,
                "updated_at": datetime.now().isoformat()
            }).execute()
            print(f"ğŸ“ˆ æƒé‡æ›´æ–°ï¼š{e['desc']} â†’ {new_weight:.2f}")
        except Exception as err:
            print(f"âš ï¸ æƒé‡ä¿å­˜å¤±è´¥ï¼š{e['desc']} | {err}")

def save_life_tags(supabase_client, user_id, life_tags):
    """ä¿å­˜æˆ–æ›´æ–°ç”¨æˆ·çš„ life_tagsï¼ˆäººç”Ÿæ ‡ç­¾ï¼‰"""
    if supabase_client is None:
        return
    
    try:
        supabase_client.table("user_life_tags").upsert({
            "user_id": user_id,
            **life_tags,
            "updated_at": datetime.now().isoformat()
        }).execute()
        print(f"ğŸ’¾ å·²ä¿å­˜ life_tags â†’ {user_id}")
    except Exception as err:
        print(f"âš ï¸ ä¿å­˜ life_tags å¤±è´¥: {err}")

# ----------------------------------------------------------
# å•å‘½ç›˜éªŒè¯é€»è¾‘
# ----------------------------------------------------------
def verify_chart(user_id: str, chart_data: dict, life_data: dict):
    chart_text = " ".join([
        chart_data.get("notes", ""),
        chart_data.get("main_star", ""),
        chart_data.get("source", ""),
        chart_data.get("birth_datetime", "")
    ])
    features = extract_features_from_chart(chart_text)
    matched, unmatched = [], []
    total_weight, gained_score = 0, 0

    for ev in life_data.get("events", []):
        desc = ev.get("desc", "")
        weight = ev.get("weight", 1.0)
        total_weight += weight

        best_sim, best_feature = 0.0, None
        for ft in features:
            sim = semantic_similarity(ft, desc)
            if sim > best_sim:
                best_sim, best_feature = sim, ft

        ev["similarity"] = best_sim
        ev["top_match_feature"] = best_feature

        if best_sim >= 0.6:
            matched.append(ev)
            gained_score += weight * best_sim
        else:
            unmatched.append(ev)

    score = round(gained_score / total_weight, 3) if total_weight else 0.0
    confidence = "é«˜" if score >= 0.85 else "ä¸­" if score >= 0.65 else "ä½"

    result = {
        "chart_id": chart_data.get("chart_id", "unknown"),
        "score": score,
        "confidence": confidence,
        "matched_keywords": list({ev["top_match_feature"] for ev in matched if ev.get("top_match_feature")}),
        "verified_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }

    # âœ… æ™ºèƒ½æƒé‡å­¦ä¹ ï¼šæ ¹æ®æœªåŒ¹é…äº‹ä»¶çš„ç›¸ä¼¼åº¦åŠ¨æ€è°ƒæ•´æƒé‡
    unmatched_events = unmatched
    if unmatched_events:
        print(f"\nğŸ§  æ™ºèƒ½æƒé‡å­¦ä¹ ä¸­... ({len(unmatched_events)} ä¸ªæœªåŒ¹é…äº‹ä»¶)")
        update_event_weights(supabase, unmatched_events)
    
    # âœ… æ„å»ºå¹¶ä¿å­˜ç”¨æˆ· life_tags åˆ°æ•°æ®åº“
    life_tags = {
        "career_type": life_data.get("career_type", ""),
        "marriage_status": life_data.get("marriage_status", ""),
        "children": life_data.get("children", 0),
        "event_count": len(life_data.get("events", []))
    }
    print(f"\nğŸ’¾ ä¿å­˜ç”¨æˆ·äººç”Ÿæ ‡ç­¾...")
    save_life_tags(supabase, user_id, life_tags)

    # âœ… å†™å…¥éªŒè¯ç»“æœåˆ° Supabase
    if supabase:
        try:
            supabase.table("verified_charts").insert({
                "user_id": user_id,
                "chart_id": result["chart_id"],
                "score": result["score"],
                "confidence": result["confidence"],
                "matched_keywords": result["matched_keywords"],
                "verified_at": result["verified_at"]
            }).execute()
            print(f"ğŸ§¾ Saved verification record for {user_id} â†’ {result['chart_id']}")
        except Exception as e:
            print("âš ï¸ Supabase insert error:", e)

    return result

# ----------------------------------------------------------
# å¤šå‘½ç›˜ç»„åˆéªŒè¯
# ----------------------------------------------------------
def verify_multiple_charts(user_id: str, charts: list, life_data: dict):
    combo_results = [verify_chart(user_id, ch, life_data) for ch in charts]
    combo_results.sort(key=lambda x: x["score"], reverse=True)
    best = combo_results[0]["chart_id"] if combo_results else None

    output = {
        "user_id": user_id,
        "combos": combo_results,
        "best_match": best,
        "verified_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }

    json.dump(output, open("./data/verified_birth_profiles.json", "w", encoding="utf-8"),
              ensure_ascii=False, indent=2)
    return output

# ----------------------------------------------------------
# ä¸»å…¥å£å‡½æ•°ï¼ˆä¾›å¤–éƒ¨è°ƒç”¨ï¼‰
# ----------------------------------------------------------
def run_truechart_verifier(user_id="u_demo", supabase_client=None):
    """
    çœŸå‘½ç›˜éªŒè¯ä¸»å‡½æ•°
    å‚æ•°ï¼š
        user_id: ç”¨æˆ·ID
        supabase_client: Supabase å®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼‰
    è¿”å›ï¼š
        éªŒè¯ç»“æœçš„ JSON å¯¹è±¡
    """
    os.makedirs("./data", exist_ok=True)
    
    # ç¤ºä¾‹æµ‹è¯•æ•°æ®
    chart_A = {
        "chart_id": "c_A",
        "source": "wenmo",
        "birth_datetime": "1975-05-10 23:10",
        "main_star": "å¤©åºœ",
        "notes": "å‘½å®«åœ¨å·³ï¼Œæ¯ç¼˜æµ…ï¼Œå©šè¿Ÿï¼Œäº‹ä¸šåˆæœ‰æ³¢æŠ˜åæˆï¼Œè´¢è¿ä¸­å¹´è§æ—º"
    }
    chart_B = {
        "chart_id": "c_B",
        "source": "wenmo",
        "birth_datetime": "1975-05-10 22:45",
        "main_star": "ç´«å¾®",
        "notes": "å‘½å®«åœ¨è¾°ï¼Œçˆ¶æ¯ç¼˜åšï¼Œå©šæ—©ä½†ç ´ï¼Œäº‹ä¸šç¨³ä¸­æœ‰è¿›"
    }
    chart_C = {
        "chart_id": "c_C",
        "source": "wenmo",
        "birth_datetime": "1975-05-10 23:30",
        "main_star": "æ­¦æ›²",
        "notes": "å‘½å®«åœ¨åˆï¼Œæ¯ç¼˜æµ…ï¼Œå©šå§»è¿Ÿæˆï¼Œäº‹ä¸šèµ·ä¼ï¼Œè´¢è¿åæ—º"
    }
    life_demo = {
        "career_type": "è®¾è®¡è¡Œä¸š",
        "marriage_status": "æ™šå©š",
        "children": 1,
        "events": [
            {"desc": "2003å¹´æ¯äº²å»ä¸–", "weight": 2.0},
            {"desc": "2006å¹´æµ·å¤–ç•™å­¦", "weight": 1.0},
            {"desc": "2010å¹´è·è®¾è®¡å¥–é¡¹", "weight": 1.5},
            {"desc": "å©šå§»æ™šæˆï¼Œå¦»å­å¹´é•¿å…«å²", "weight": 1.2}
        ]
    }
    
    charts = [chart_A, chart_B, chart_C]
    
    # ä½¿ç”¨ä¼ å…¥çš„ supabase å®¢æˆ·ç«¯æˆ–å…¨å±€çš„ supabase
    global supabase
    if supabase_client:
        supabase = supabase_client
    
    result = verify_multiple_charts(user_id, charts, life_demo)
    return result

# ----------------------------------------------------------
# æ‰‹åŠ¨æµ‹è¯•
# ----------------------------------------------------------
if __name__ == "__main__":
    result = run_truechart_verifier("u_demo")
    print(json.dumps(result, ensure_ascii=False, indent=2))
