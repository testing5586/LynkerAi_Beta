# ==========================================================
# LynkerAI TrueChart Verifier v3.1
# AIè®°å¿†æ•°æ®åº“ç‰ˆï¼ˆSupabase å†™å…¥æœºåˆ¶ï¼‰
# ==========================================================

import json, os, re
from datetime import datetime
from sentence_transformers import SentenceTransformer, util
from supabase import create_client, Client

# ----------------------------------------------------------
# åŠ è½½æ¨¡å‹
# ----------------------------------------------------------
print("ğŸ§  Loading high-semantic Chinese model (shibing624/text2vec-base-chinese)...")
model = SentenceTransformer("shibing624/text2vec-base-chinese")
print("âœ… Model loaded successfully!")

# ----------------------------------------------------------
# åˆå§‹åŒ– Supabase å®¢æˆ·ç«¯
# ----------------------------------------------------------
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

supabase: Client = None
if SUPABASE_URL and SUPABASE_KEY:
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    print("ğŸ”— Connected to Supabase!")
else:
    print("âš ï¸ Warning: Supabase credentials not found. Results will only be saved locally.")

# ----------------------------------------------------------
# è¾…åŠ©å‡½æ•°
# ----------------------------------------------------------
def semantic_similarity(a: str, b: str) -> float:
    emb1 = model.encode(a, convert_to_tensor=True)
    emb2 = model.encode(b, convert_to_tensor=True)
    return round(float(util.pytorch_cos_sim(emb1, emb2).item()), 4)

def extract_features_from_chart(chart_text: str):
    patterns = {
        "æ¯ç¼˜æµ…": r"(æ¯|æ¯äº²|å¥³æ€§é•¿è¾ˆ).{0,4}(äº¡|å»ä¸–|ç¼˜è–„|ä¸åˆ©)",
        "å©šè¿Ÿ": r"(å©š|é…å¶|å¤«å¦»).{0,4}(æ™š|è¿Ÿ|éš¾|ç ´)",
        "äº‹ä¸šæ³¢æŠ˜": r"(äº‹|ä¸š|å·¥ä½œ|å®˜ç¦„).{0,4}(æ³¢æŠ˜|å¤šå˜|èµ·ä¼|ç ´)",
        "è´¢è¿å¥½": r"(è´¢|é’±|æ”¶å…¥).{0,4}(æ—º|ä½³|å¥½|ç¨³)",
        "å¥åº·å¼±": r"(ç–¾|ç—…|èº«|å¥åº·).{0,4}(å¼±|ä¸ä½³|å—æŸ)",
    }
    features = [k for k, p in patterns.items() if re.search(p, chart_text)]
    raw_terms = re.findall(r"[\u4e00-\u9fa5]{2,6}", chart_text)
    features.extend(list(set(raw_terms[:50])))
    return list(set(features))

# ----------------------------------------------------------
# å•å‘½ç›˜éªŒè¯é€»è¾‘
# ----------------------------------------------------------
def verify_chart(user_id: str, chart_data: dict, life_data: dict):
    chart_text = " ".join([
        chart_data.get("notes", ""),
        chart_data.get("main_star", ""),
        chart_data.get("source", ""),
        chart_data.get("birth_datetime", "")
    ])
    features = extract_features_from_chart(chart_text)
    matched, unmatched = [], []
    total_weight, gained_score = 0, 0

    for ev in life_data.get("events", []):
        desc = ev.get("desc", "")
        weight = ev.get("weight", 1.0)
        total_weight += weight

        best_sim, best_feature = 0.0, None
        for ft in features:
            sim = semantic_similarity(ft, desc)
            if sim > best_sim:
                best_sim, best_feature = sim, ft

        ev["similarity"] = best_sim
        ev["top_match_feature"] = best_feature

        if best_sim >= 0.6:
            matched.append(ev)
            gained_score += weight * best_sim
        else:
            unmatched.append(ev)

    score = round(gained_score / total_weight, 3) if total_weight else 0.0
    confidence = "é«˜" if score >= 0.85 else "ä¸­" if score >= 0.65 else "ä½"

    result = {
        "chart_id": chart_data.get("chart_id", "unknown"),
        "score": score,
        "confidence": confidence,
        "matched_keywords": list({ev["top_match_feature"] for ev in matched if ev.get("top_match_feature")}),
        "verified_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }

    # âœ… å†™å…¥ Supabase
    if supabase:
        try:
            supabase.table("verified_charts").insert({
                "user_id": user_id,
                "chart_id": result["chart_id"],
                "score": result["score"],
                "confidence": result["confidence"],
                "matched_keywords": result["matched_keywords"],
                "verified_at": result["verified_at"]
            }).execute()
            print(f"ğŸ§¾ Saved verification record for {user_id} â†’ {result['chart_id']}")
        except Exception as e:
            print("âš ï¸ Supabase insert error:", e)

    return result

# ----------------------------------------------------------
# å¤šå‘½ç›˜ç»„åˆéªŒè¯
# ----------------------------------------------------------
def verify_multiple_charts(user_id: str, charts: list, life_data: dict):
    combo_results = [verify_chart(user_id, ch, life_data) for ch in charts]
    combo_results.sort(key=lambda x: x["score"], reverse=True)
    best = combo_results[0]["chart_id"] if combo_results else None

    output = {
        "user_id": user_id,
        "combos": combo_results,
        "best_match": best,
        "verified_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }

    json.dump(output, open("./data/verified_birth_profiles.json", "w", encoding="utf-8"),
              ensure_ascii=False, indent=2)
    return output

# ----------------------------------------------------------
# æ‰‹åŠ¨æµ‹è¯•
# ----------------------------------------------------------
if __name__ == "__main__":
    os.makedirs("./data", exist_ok=True)
    chart_A = {
        "chart_id": "c_A",
        "source": "wenmo",
        "birth_datetime": "1975-05-10 23:10",
        "main_star": "å¤©åºœ",
        "notes": "å‘½å®«åœ¨å·³ï¼Œæ¯ç¼˜æµ…ï¼Œå©šè¿Ÿï¼Œäº‹ä¸šåˆæœ‰æ³¢æŠ˜åæˆï¼Œè´¢è¿ä¸­å¹´è§æ—º"
    }
    chart_B = {
        "chart_id": "c_B",
        "source": "wenmo",
        "birth_datetime": "1975-05-10 22:45",
        "main_star": "ç´«å¾®",
        "notes": "å‘½å®«åœ¨è¾°ï¼Œçˆ¶æ¯ç¼˜åšï¼Œå©šæ—©ä½†ç ´ï¼Œäº‹ä¸šç¨³ä¸­æœ‰è¿›"
    }
    chart_C = {
        "chart_id": "c_C",
        "source": "wenmo",
        "birth_datetime": "1975-05-10 23:30",
        "main_star": "æ­¦æ›²",
        "notes": "å‘½å®«åœ¨åˆï¼Œæ¯ç¼˜æµ…ï¼Œå©šå§»è¿Ÿæˆï¼Œäº‹ä¸šèµ·ä¼ï¼Œè´¢è¿åæ—º"
    }
    life_demo = {
        "career_type": "è®¾è®¡è¡Œä¸š",
        "marriage_status": "æ™šå©š",
        "children": 1,
        "events": [
            {"desc": "2003å¹´æ¯äº²å»ä¸–", "weight": 2.0},
            {"desc": "2006å¹´æµ·å¤–ç•™å­¦", "weight": 1.0},
            {"desc": "2010å¹´è·è®¾è®¡å¥–é¡¹", "weight": 1.5},
            {"desc": "å©šå§»æ™šæˆï¼Œå¦»å­å¹´é•¿å…«å²", "weight": 1.2}
        ]
    }
    charts = [chart_A, chart_B, chart_C]
    print(json.dumps(verify_multiple_charts("u_demo", charts, life_demo), ensure_ascii=False, indent=2))
