# ================================
# Phase 3.2 + 3.3：RAG Chat + 向量检索（中文免费方案）
# ================================

echo "📦 安装依赖（如已安装会自动跳过）..."
pip -q install faiss-cpu sentence-transformers jieba pdfminer.six python-docx > /dev/null 2>&1 || true

# ---------- 1) 向量索引器：扫描 Vault、分块、嵌入、保存 ----------
cat > vector_indexer.py << 'PY'
import os, json, re, time, argparse
from pathlib import Path
from sentence_transformers import SentenceTransformer
import numpy as np
import faiss
from pdfminer.high_level import extract_text as pdf_extract
from docx import Document

VAULT_DIR = Path("lynker_master_vault")
VSTORE_DIR = VAULT_DIR / "vector_store"
VSTORE_DIR.mkdir(parents=True, exist_ok=True)
INDEX_FILE = VSTORE_DIR / "faiss.index"
META_FILE  = VSTORE_DIR / "meta.json"

# 缓存模型（与项目其它处一致的免费中文向量模型）
_model = None
def get_model():
    global _model
    if _model is None:
        print("🧠 Loading embedding model (cached if same process)...")
        _model = SentenceTransformer("shibing624/text2vec-base-chinese")
    return _model

def read_text(path: Path) -> str:
    p = str(path).lower()
    try:
        if p.endswith(".md") or p.endswith(".txt"):
            return path.read_text(encoding="utf-8", errors="ignore")
        if p.endswith(".pdf"):
            return pdf_extract(str(path))
        if p.endswith(".docx"):
            doc = Document(str(path))
            return "\n".join([p.text for p in doc.paragraphs])
    except Exception as e:
        print(f"⚠️ 读取失败 {path.name}: {e}")
    return ""

def split_chunks(text, chunk_size=600, overlap=120):
    text = re.sub(r"\s+", " ", text).strip()
    if not text: return []
    chunks = []
    start = 0
    while start < len(text):
        end = min(len(text), start + chunk_size)
        chunks.append(text[start:end])
        start = end - overlap
        if start < 0:
            start = 0
        if end == len(text): break
    return chunks

def scan_docs():
    exts = (".md", ".txt", ".pdf", ".docx")
    for cat in ["project_docs", "dev_brainstorm", "api_docs", "memory"]:
        folder = VAULT_DIR / cat
        if not folder.exists(): continue
        for f in folder.glob("*"):
            if f.is_file() and f.suffix.lower() in exts:
                yield cat, f

def build_or_update(rebuild=False):
    meta = {"items": []}
    xb = None
    index = None

    if (INDEX_FILE.exists() and META_FILE.exists() and not rebuild):
        # 增量载入
        print("🔁 Loading existing index for incremental update...")
        index = faiss.read_index(str(INDEX_FILE))
        meta = json.loads(META_FILE.read_text(encoding="utf-8"))

    model = get_model()
    added = 0
    for cat, f in scan_docs():
        # 跳过已索引的文件（简易判断：看是否已有相同 file_id）
        file_id = f"{cat}/{f.name}"
        if not rebuild and any(it["file_id"] == file_id for it in meta["items"]):
            continue

        txt = read_text(f)
        chunks = split_chunks(txt)
        if not chunks: 
            continue
        embs = model.encode(chunks, normalize_embeddings=True)
        embs = np.array(embs, dtype="float32")

        if index is None:
            index = faiss.IndexFlatIP(embs.shape[1])  # 余弦相似度用内积（已normalize）
        index.add(embs)

        # 记录 metadata
        for i, c in enumerate(chunks):
            meta["items"].append({
                "file_id": file_id,
                "category": cat,
                "chunk_id": i,
                "text": c
            })
        added += len(chunks)
        print(f"📚 Indexed: {file_id} ({len(chunks)} chunks)")

    if index is None:
        print("⚠️ 没有文档可索引。")
        return

    faiss.write_index(index, str(INDEX_FILE))
    META_FILE.write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"✅ 索引完成：{len(meta['items'])} chunks | 新增 {added} chunks")

if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--rebuild", action="store_true", help="重建索引（忽略历史）")
    args = ap.parse_args()
    t0 = time.time()
    build_or_update(rebuild=args.rebuild)
    print(f"⏱️ 用时：{time.time()-t0:.2f}s")
PY
echo "✅ vector_indexer.py 已创建"

# ---------- 2) 向量检索器：加载索引、TopK 搜索 ----------
cat > vector_search.py << 'PY'
import json, numpy as np
from pathlib import Path
from sentence_transformers import SentenceTransformer
import faiss

VAULT_DIR = Path("lynker_master_vault")
VSTORE_DIR = VAULT_DIR / "vector_store"
INDEX_FILE = VSTORE_DIR / "faiss.index"
META_FILE  = VSTORE_DIR / "meta.json"

_model = None
_index = None
_meta  = None

def get_model():
    global _model
    if _model is None:
        _model = SentenceTransformer("shibing624/text2vec-base-chinese")
    return _model

def load_store():
    global _index, _meta
    if _index is None:
        _index = faiss.read_index(str(INDEX_FILE))
    if _meta is None:
        _meta = json.loads(META_FILE.read_text(encoding="utf-8"))
    return _index, _meta

def search(query: str, topk=5):
    model = get_model()
    index, meta = load_store()
    q = model.encode([query], normalize_embeddings=True).astype("float32")
    D, I = index.search(q, topk)
    hits = []
    for score, idx in zip(D[0], I[0]):
        if idx < 0 or idx >= len(meta["items"]): continue
        item = meta["items"][idx]
        hits.append({
            "score": float(score),
            **item
        })
    return hits

if __name__ == "__main__":
    from pprint import pprint
    if not INDEX_FILE.exists():
        print("⚠️ 索引不存在，请先运行：python vector_indexer.py --rebuild")
    else:
        pprint(search("同命匹配 与 八字 验证"))
PY
echo "✅ vector_search.py 已创建"

# ---------- 3) Chat 页面（纯前端） ----------
cat > static_chat.html << 'HTML'
<!DOCTYPE html>
<html lang="zh">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<title>Lynker Master AI — Chat</title>
<style>
  body{font-family:Inter,system-ui,-apple-system; background:#0f111a; color:#e5e5e5; margin:0;}
  .wrap{max-width:900px;margin:0 auto;padding:24px;}
  .header{display:flex;gap:12px;align-items:center;justify-content:space-between}
  .btn{background:#6B46C1;border:0;color:#fff;padding:10px 14px;border-radius:10px;cursor:pointer}
  .pill{background:#6936f31a;border:1px solid #6B46C1;color:#cbb6ff;padding:6px 10px;border-radius:999px}
  .box{background:#151826;border:1px solid #2a2e45;border-radius:16px;padding:16px;margin-top:16px}
  .msg{padding:12px 14px;border-radius:12px;margin:8px 0}
  .user{background:#1f2340}
  .ai{background:#161a2e}
  .sources{font-size:12px;color:#a8b3cf}
</style>
</head>
<body>
  <div class="wrap">
    <div class="header">
      <h2>💬 Lynker Master AI</h2>
      <div>
        <a class="pill" href="/api/master-ai/context" target="_blank">📚 Vault</a>
        <a class="pill" href="/api/master-ai/upload-stats" target="_blank">📊 Stats</a>
        <a class="btn" href="/upload">📤 上传到 Vault</a>
      </div>
    </div>

    <div id="chat" class="box"></div>

    <div class="box">
      <input id="q" placeholder="例如：请根据Vault说明，帮我描述‘真命盘验证’的核心流程" style="width:100%;padding:12px;border-radius:10px;border:1px solid #2a2e45;background:#0f111a;color:#e5e5e5"/>
      <button class="btn" style="margin-top:12px" onclick="ask()">发送</button>
    </div>
  </div>

<script>
const chat = document.getElementById('chat');
function push(role, text){
  const d = document.createElement('div');
  d.className = 'msg ' + (role==='user'?'user':'ai');
  d.innerHTML = text;
  chat.appendChild(d);
  chat.scrollTop = chat.scrollHeight;
}
async function ask(){
  const q = document.getElementById('q').value.trim();
  if(!q) return;
  push('user', '🧑‍💻 ' + q);
  document.getElementById('q').value = '';
  const res = await fetch('/api/master-ai/chat', {
    method:'POST', headers:{'Content-Type':'application/json'},
    body: JSON.stringify({query:q, topk:5})
  });
  const data = await res.json();
  if(data.status==='ok'){
    let s = '🤖 ' + data.answer;
    if(data.citations && data.citations.length){
      s += '<div class="sources">参考片段：<ul>'
      for(const c of data.citations){
        s += '<li>['+c.category+'] ' + c.file_id + ' #'+c.chunk_id+'（相关度'+c.score.toFixed(3)+'）</li>';
      }
      s += '</ul></div>';
    }
    push('ai', s);
  }else{
    push('ai', '⚠️ ' + data.message);
  }
}
</script>
</body>
</html>
HTML
echo "✅ Chat 前端 static_chat.html 已创建"

# ---------- 4) 将 Chat API & RAG 集成到现有 master_ai_uploader_api.py ----------
python - << 'PY'
import io, re, sys, os, json
p="master_ai_uploader_api.py"
src=open(p,"r",encoding="utf-8").read()

# 若已集成则跳过
if "/api/master-ai/chat" in src and "static_chat.html" in src:
    print("ℹ️ master_ai_uploader_api.py 已包含 Chat 路由，跳过修改。")
    sys.exit(0)

injection = r'''
# === RAG Chat 依赖 ===
from flask import send_file, jsonify
from vector_search import search as rag_search
from vector_indexer import build_or_update as rag_reindex

@app.route("/chat")
def chat_page():
    # 简单地返回静态HTML（已内嵌脚本与样式）
    return send_file("static_chat.html")

@app.route("/api/master-ai/chat", methods=["POST"])
def master_ai_chat():
    """RAG：从 Vault 中检索相关片段并生成简要回答（无外部LLM，摘要模板式）"""
    try:
        data = request.get_json(force=True)
        query = (data.get("query") or "").strip()
        topk  = int(data.get("topk") or 5)
        if not query:
            return jsonify({"status":"error","message":"缺少 query"}), 400

        # 检索
        hits = rag_search(query, topk=topk)
        if not hits:
            return jsonify({"status":"ok","answer":"没有在 Vault 中找到相关资料。", "citations":[]})

        # 组装一个模板式的“回答”
        bullets = []
        for h in hits:
            txt = h["text"].strip()
            if len(txt)>180: txt = txt[:180]+"..."
            bullets.append(f"• 来自《{h['file_id']}》：{txt}")
        answer = "基于知识库检索，我找到以下要点：\n" + "\n".join(bullets) + "\n\n（以上为自动检索摘要，详情请查看引用片段与原文档）"

        return jsonify({"status":"ok","answer":answer,"citations":hits})
    except Exception as e:
        return jsonify({"status":"error","message":str(e)}), 500
'''

# 在文件末尾前插入（保留原接口）
src = src + "\n" + injection

open(p,"w",encoding="utf-8").write(src)
print("✅ 已向 master_ai_uploader_api.py 注入 Chat 路由与 RAG API")
PY

# ---------- 5) 在上传成功后自动触发“增量向量更新” ----------
python - << 'PY'
p="master_ai_uploader_api.py"
s=open(p,"r",encoding="utf-8").read()
anchor="result = subprocess.getoutput(f\"python master_ai_importer.py {filepath}\")"
if anchor in s and "rag_reindex()" not in s:
    s=s.replace(anchor, anchor + "\n\n    # 向量库增量更新（仅索引新文件）\n    try:\n        rag_reindex(rebuild=False)\n    except Exception as _e:\n        print(f\"⚠️ 向量库增量更新失败：{_e}\")\n")
    open(p,"w",encoding="utf-8").write(s)
    print("✅ 上传后已接入向量库增量更新")
else:
    print("ℹ️ 已存在增量更新或未找到注入点，跳过。")
PY

# ---------- 6) 首次全量构建向量索引 ----------
echo "🔧 正在全量构建向量索引（如无文档会提示0）..."
python vector_indexer.py --rebuild

# ---------- 7) 启动主服务（端口沿用你当前的 8008） ----------
echo "🚀 启动主服务：/upload、/api/master-ai/*、/chat 全部在同一应用中"
python master_ai_uploader_api.py
