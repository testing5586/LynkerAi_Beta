"""
child_ai_memory.py
------------------------------------
ğŸ“˜ åŠŸèƒ½ï¼š
Lynker å­AIè®°å¿†ä»“åº“ç³»ç»Ÿ

ä» child_ai_insights æå–ä¿¡æ¯ï¼Œ
è‡ªåŠ¨ç”Ÿæˆè®°å¿†æ‘˜è¦ï¼Œ
ä¿å­˜è‡³ Supabase æˆ–æœ¬åœ° JSONï¼Œ
å¹¶é¢„ç•™ Google Drive åŒæ­¥æ¥å£ã€‚
------------------------------------
è¿è¡Œæ–¹å¼ï¼š
python child_ai_memory.py
"""

import json, os
from datetime import datetime

try:
    from supabase_init import get_supabase
    supabase = get_supabase()
except Exception as e:
    supabase = None
    print(f"âš ï¸ Supabaseè¿æ¥å¤±è´¥ï¼Œè½¬ä¸ºæœ¬åœ°æ¨¡å¼: {e}")


# âœ… æœ¬åœ°å¤‡ä»½å‡½æ•°
def save_local_backup(filename, data):
    os.makedirs("./data", exist_ok=True)
    with open(f"./data/{filename}", "a", encoding="utf-8") as f:
        f.write(json.dumps(data, ensure_ascii=False) + "\n")
    print(f"ğŸ’¾ æœ¬åœ°å¤‡ä»½ â†’ {filename}")


# âœ… é¢„ç•™ Google Drive æ¥å£
def save_to_google_drive(user_id, memory_record):
    """
    ğŸ“‚ æœªæ¥åŠŸèƒ½ï¼šç”¨æˆ·æˆæƒåå†™å…¥ Google Drive
    Scope: https://www.googleapis.com/auth/drive.file
    Path: My Drive / LynkerAI / memory / u_{user_id}_memory.json
    """
    # TODO: Integrate OAuth 2.0 + Drive API
    print(f"â˜ï¸ [é¢„ç•™] å°†å†™å…¥ Google Driveï¼š{user_id} - {memory_record['summary']}")


# âœ… ä» child_ai_insights æå–ç”¨æˆ·çš„åŒ¹é…è®°å¿†
def extract_ai_memories(user_id):
    if not supabase:
        print("âš ï¸ æ— æ³•è¿æ¥ Supabaseï¼Œä½¿ç”¨æœ¬åœ°æ¨¡å¼ã€‚")
        return []

    resp = supabase.table("child_ai_insights").select("*").eq("user_id", user_id).execute()
    data = resp.data if resp and resp.data else []
    if not data:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ´å¯Ÿè®°å½•ã€‚")
        return []

    memories = []
    for record in data:
        partner = record.get("partner_id", "æœªçŸ¥")
        # ğŸ§© è‡ªåŠ¨å±•å¼€ shared_tags çš„å„ç§ç±»å‹ç»“æ„
        tags = record.get("shared_tags", [])

        # è‹¥æ˜¯å­—ç¬¦ä¸² â†’ å°è¯•ååºåˆ—åŒ–
        if isinstance(tags, str):
            try:
                tags = json.loads(tags)
            except:
                tags = [tags]

        # è‹¥æ˜¯ dict â†’ å–å€¼
        if isinstance(tags, dict):
            tags = list(tags.values())

        # è‹¥æ˜¯åµŒå¥— list â†’ å±•å¹³
        if isinstance(tags, list):
            flat_tags = []
            for t in tags:
                if isinstance(t, list):
                    flat_tags.extend(t)
                elif isinstance(t, dict):
                    flat_tags.extend(list(t.values()))
                else:
                    flat_tags.append(str(t))
            tags = flat_tags

        # ç»Ÿä¸€è½¬å­—ç¬¦ä¸²
        tags_str = "ã€".join([str(t) for t in tags if t])
        sim = round(record.get("similarity", 0.0), 3)
        summary = f"ä¸ {partner} å…±é¸£ ({sim})ï¼š{tags_str}"
        memories.append({
            "user_id": user_id,
            "partner_id": partner,
            "tags": tags,
            "summary": summary,
            "created_at": datetime.now().isoformat()
        })
    print(f"ğŸ§  å·²æå– {len(memories)} æ¡AIè®°å¿†ã€‚")
    return memories


# âœ… ä¿å­˜è‡³ Supabase
def save_ai_memories(user_id, memories):
    if not memories:
        print("âš ï¸ æ²¡æœ‰å¯ä¿å­˜çš„è®°å¿†ã€‚")
        return

    for mem in memories:
        try:
            if supabase:
                supabase.table("child_ai_memory").insert(mem).execute()
                print(f"ğŸ’¾ å·²ä¿å­˜è‡³ Supabase.child_ai_memory â†’ {mem['partner_id']}")
            else:
                save_local_backup("child_ai_memory_backup.jsonl", mem)
            # â˜ï¸ å¯é€‰æœªæ¥åŒæ­¥
            # save_to_google_drive(user_id, mem)
        except Exception as e:
            print(f"âš ï¸ Supabaseå†™å…¥å¤±è´¥ï¼Œä¿å­˜æœ¬åœ°ï¼š{e}")
            save_local_backup("child_ai_memory_backup.jsonl", mem)


# âœ… ä¸»æ‰§è¡Œå‡½æ•°
def run_child_ai_memory(user_id="u_demo"):
    print(f"ğŸ“œ å­AIè®°å¿†ç”Ÿæˆä¸­ï¼š{user_id}")
    memories = extract_ai_memories(user_id)
    save_ai_memories(user_id, memories)
    print("âœ… å­AIè®°å¿†åŒæ­¥å®Œæˆã€‚")


# âœ… æµ‹è¯•è¿è¡Œ
if __name__ == "__main__":
    run_child_ai_memory("u_demo")
