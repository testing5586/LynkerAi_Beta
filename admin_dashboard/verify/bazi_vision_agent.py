# -*- coding: utf-8 -*-
"""
Bazi Vision Agent - ä¸‰å±‚æ™ºèƒ½å…«å­—è¯†åˆ«ç³»ç»Ÿ
Layer 1: Vision Agent - ä½¿ç”¨ MiniMax Vision Pro / GPT-4 Vision / æœ¬åœ°æ¨¡æ‹Ÿ
Layer 2: Normalizer Agent - æ ‡å‡†åŒ–å››æŸ±æ•°æ®
Layer 3: Formatter Agent - æ ¼å¼åŒ–è¾“å‡º
"""

import os
import json
import requests
import base64
from typing import Dict, List, Optional, Tuple
from openai import OpenAI

class BaziVisionAgent:
    """ä¸‰å±‚å…«å­—è¯†åˆ«ä»£ç†ç³»ç»Ÿ"""
    
    def __init__(self):
        self.minimax_api_key = os.getenv("MINIMAX_API_KEY")
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.openai_client = OpenAI(api_key=self.openai_api_key) if self.openai_api_key else None
        
        # MiniMax å®˜æ–¹ç«¯ç‚¹åˆ—è¡¨ï¼ˆæ”¯æŒå…¨çƒè®¿é—®ï¼‰
        self.minimax_endpoints = [
            "https://api.minimaxi.com/v1/chat/completions",  # ä¸­å›½åŒºï¼ˆä¼˜å…ˆï¼‰
            "https://api.minimax.io/v1/chat/completions"     # å›½é™…åŒº
        ]
        self.last_successful_endpoint = None  # è®°å½•ä¸Šæ¬¡æˆåŠŸçš„ç«¯ç‚¹
        
        # å¤©å¹²åœ°æ”¯æ˜ å°„
        self.tiangan = ["ç”²", "ä¹™", "ä¸™", "ä¸", "æˆŠ", "å·±", "åºš", "è¾›", "å£¬", "ç™¸"]
        self.dizhi = ["å­", "ä¸‘", "å¯…", "å¯", "è¾°", "å·³", "åˆ", "æœª", "ç”³", "é…‰", "æˆŒ", "äº¥"]
        self.wuxing_map = {
            "ç”²": "æœ¨", "ä¹™": "æœ¨", "ä¸™": "ç«", "ä¸": "ç«", "æˆŠ": "åœŸ", 
            "å·±": "åœŸ", "åºš": "é‡‘", "è¾›": "é‡‘", "å£¬": "æ°´", "ç™¸": "æ°´",
            "å­": "æ°´", "ä¸‘": "åœŸ", "å¯…": "æœ¨", "å¯": "æœ¨", "è¾°": "åœŸ", 
            "å·³": "ç«", "åˆ": "ç«", "æœª": "åœŸ", "ç”³": "é‡‘", "é…‰": "é‡‘", 
            "æˆŒ": "åœŸ", "äº¥": "æ°´"
        }
    
    def process_image(self, image_base64: str, progress_callback=None) -> Dict:
        """
        å¤„ç†å…«å­—å›¾ç‰‡ï¼Œè¿”å›è¯†åˆ«ç»“æœ
        
        Args:
            image_base64: Base64 ç¼–ç çš„å›¾ç‰‡æ•°æ®
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•° callback(message: str)
        
        Returns:
            è¯†åˆ«ç»“æœå­—å…¸
        """
        try:
            if progress_callback:
                progress_callback("ğŸ¯ å¼€å§‹ä¸‰å±‚æ™ºèƒ½è¯†åˆ«æµç¨‹...")
            
            # Layer 1: Vision Agent - å›¾ç‰‡è¯†åˆ«
            raw_text = self._vision_layer(image_base64, progress_callback)
            
            # Layer 2: Normalizer Agent - æ ‡å‡†åŒ–æ•°æ®
            normalized_data = self._normalizer_layer(raw_text, progress_callback)
            
            # Layer 3: Formatter Agent - æ ¼å¼åŒ–è¾“å‡º
            formatted_result = self._formatter_layer(normalized_data, progress_callback)
            
            if progress_callback:
                progress_callback("âœ… ä¸‰å±‚è¯†åˆ«å®Œæˆï¼")
            
            return {
                "success": True,
                "data": formatted_result,
                "raw_text": raw_text
            }
            
        except Exception as e:
            error_msg = f"è¯†åˆ«å¤±è´¥: {str(e)}"
            if progress_callback:
                progress_callback(f"âŒ {error_msg}")
            return {
                "success": False,
                "error": error_msg
            }
    
    def _vision_layer(self, image_base64: str, progress_callback=None) -> str:
        """Layer 1: Vision Agent - å›¾ç‰‡è¯†åˆ«ï¼ˆä¸‰çº§ fallbackï¼‰"""
        
        # å°è¯• 1: MiniMax Vision Pro
        if self.minimax_api_key:
            try:
                if progress_callback:
                    progress_callback("ğŸ“¸ ä½¿ç”¨ MiniMax Vision Pro è¯†åˆ«...")
                result = self._call_minimax_vision(image_base64)
                if result:
                    if progress_callback:
                        progress_callback("âœ… MiniMax è¯†åˆ«æˆåŠŸ")
                    return result
            except Exception as e:
                if progress_callback:
                    progress_callback(f"âš ï¸ MiniMax å¤±è´¥: {str(e)}")
        
        # å°è¯• 2: GPT-4 Vision
        if self.openai_client:
            try:
                if progress_callback:
                    progress_callback("ğŸ“¸ åˆ‡æ¢åˆ° GPT-4 Vision...")
                result = self._call_gpt4_vision(image_base64)
                if result:
                    if progress_callback:
                        progress_callback("âœ… GPT-4 Vision è¯†åˆ«æˆåŠŸ")
                    return result
            except Exception as e:
                if progress_callback:
                    progress_callback(f"âš ï¸ GPT-4 Vision å¤±è´¥: {str(e)}")
        
        # å°è¯• 3: æœ¬åœ°æ¨¡æ‹Ÿæ•°æ®
        if progress_callback:
            progress_callback("âš™ï¸ ä½¿ç”¨æœ¬åœ°æ¨¡æ‹Ÿæ•°æ®...")
        return self._get_simulated_data()
    
    def _call_minimax_vision(self, image_base64: str) -> Optional[str]:
        """
        è°ƒç”¨ MiniMax Vision Pro APIï¼ˆæ™ºèƒ½ç«¯ç‚¹åˆ‡æ¢ï¼‰
        æ”¯æŒä¸­å›½åŒºå’Œå›½é™…åŒºè‡ªåŠ¨åˆ‡æ¢
        """
        # ä¼˜å…ˆä½¿ç”¨ä¸Šæ¬¡æˆåŠŸçš„ç«¯ç‚¹
        if self.last_successful_endpoint:
            endpoints_to_try = [self.last_successful_endpoint] + [
                ep for ep in self.minimax_endpoints if ep != self.last_successful_endpoint
            ]
        else:
            endpoints_to_try = self.minimax_endpoints
        
        last_error = None
        for endpoint in endpoints_to_try:
            try:
                result = self._call_minimax_with_endpoint(endpoint, image_base64)
                self.last_successful_endpoint = endpoint  # è®°å½•æˆåŠŸçš„ç«¯ç‚¹
                return result
            except Exception as e:
                last_error = str(e)
                continue
        
        # æ‰€æœ‰ç«¯ç‚¹éƒ½å¤±è´¥
        raise Exception(f"æ‰€æœ‰ MiniMax ç«¯ç‚¹å‡ä¸å¯ç”¨ã€‚æœ€åé”™è¯¯: {last_error}")
    
    def _call_minimax_with_endpoint(self, url: str, image_base64: str) -> str:
        """ä½¿ç”¨æŒ‡å®šç«¯ç‚¹è°ƒç”¨ MiniMax Vision API"""
        # ç§»é™¤å¯èƒ½çš„ data:image å‰ç¼€
        if "," in image_base64:
            image_base64 = image_base64.split(",", 1)[1]
        
        headers = {
            "Authorization": f"Bearer {self.minimax_api_key}",
            "Content-Type": "application/json"
        }
        
        # ä½¿ç”¨ OpenAI-compatible messages æ ¼å¼
        payload = {
            "model": "minimax-vl-01",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": """ä½ æ˜¯ä¸€åä¸“ä¸šçš„å…«å­—å‘½ç›˜è¯†åˆ«ä¸“å®¶ï¼Œæ“…é•¿è¯»å–æ–‡å¢¨å¤©æœºç­‰ç³»ç»Ÿå¯¼å‡ºçš„å‘½ç›˜å›¾ç‰‡ã€‚

ğŸ“¸ è¾“å…¥å†…å®¹ï¼šå…«å­—å‘½ç›˜æˆªå›¾ï¼ˆå«å¹´æŸ±ã€æœˆæŸ±ã€æ—¥æŸ±ã€æ—¶æŸ±åŠå„å±‚ä¿¡æ¯ï¼‰
ğŸ¯ è¾“å‡ºç›®æ ‡ï¼šè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºè¯†åˆ«ç»“æœï¼Œä»¥ JSON ç»“æ„è¡¨ç¤ºè¡¨æ ¼å†…å®¹ã€‚

ã€è¯†åˆ«é‡ç‚¹ã€‘
å¿…é¡»è¯†åˆ«å‡ºä»¥ä¸‹10è¡Œï¼š
ä¸»æ˜Ÿã€å¤©å¹²ã€åœ°æ”¯ã€è—å¹²ã€å‰¯æ˜Ÿã€æ˜Ÿè¿ã€è‡ªåã€ç©ºäº¡ã€çº³éŸ³ã€ç¥ç…ã€‚

ã€è¾“å‡ºJSONæ ¼å¼è¦æ±‚ã€‘
{
  "columns": ["å¹´æŸ±","æœˆæŸ±","æ—¥æŸ±","æ—¶æŸ±"],
  "rows": {
    "ä¸»æ˜Ÿ": ["","","",""],
    "å¤©å¹²": ["","","",""],
    "åœ°æ”¯": ["","","",""],
    "è—å¹²": ["","","",""],
    "å‰¯æ˜Ÿ": ["","","",""],
    "æ˜Ÿè¿": ["","","",""],
    "è‡ªå": ["","","",""],
    "ç©ºäº¡": ["","","",""],
    "çº³éŸ³": ["","","",""],
    "ç¥ç…": ["","","",""]
  }
}

ã€æ ¼å¼è¯´æ˜ã€‘
- æ¯ä¸ªé¡¹ç›®å¯¹åº”å››ä¸ªæŸ±ï¼ˆå¹´ã€æœˆã€æ—¥ã€æ—¶ï¼‰ï¼ŒåŠ¡å¿…ä¿è¯åˆ—æ•°ä¸€è‡´ï¼›
- è‹¥æœ‰å¤šä¸ªé¡¹ç›®ï¼ˆå¦‚è—å¹²ã€å‰¯æ˜Ÿã€ç¥ç…ï¼‰ï¼Œè¯·ç”¨ä¸­æ–‡é¡¿å·"ã€"éš”å¼€ï¼›
- ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ–‡å­—ã€å•ä½æˆ–å¤šä½™å­—æ®µï¼›
- æœ€ç»ˆè¾“å‡ºå¿…é¡»æ˜¯å¯ä»¥è¢« JSON.parse() ç›´æ¥è§£æçš„çº¯JSONã€‚

ã€ç¤ºä¾‹ã€‘
| æ—¥æœŸ     | å¹´æŸ±       | æœˆæŸ±       | æ—¥æŸ±                   | æ—¶æŸ±                |
| :----- | :------- | :------- | :------------------- | :---------------- |
| **ä¸»æ˜Ÿ** | æ­£è´¢       | é£Ÿç¥       | å…ƒç”·                   | æ­£å°                |
| **å¤©å¹²** | åºš        | å·±        | ä¸                    | ç”²                 |
| **åœ°æ”¯** | è¾°        | å¯        | ä¸‘                    | è¾°                 |
| **è—å¹²** | æˆŠåœŸã€ä¹™æœ¨ã€ç™¸æ°´ | ä¹™æœ¨       | å·±åœŸã€ç™¸æ°´ã€è¾›é‡‘             | æˆŠåœŸã€ä¹™æœ¨ã€ç™¸æ°´          |
| **å‰¯æ˜Ÿ** | ä¼¤å®˜ã€åå°ã€ä¸ƒæ€ | åå°       | é£Ÿç¥ã€ä¸ƒæ€ã€åè´¢             | ä¼¤å®˜ã€åå°ã€ä¸ƒæ€          |
| **æ˜Ÿè¿** | è¡°        | ç—…        | å¢“                    | è¡°                 |
| **è‡ªå** | å…»        | ç—…        | å¢“                    | è¡°                 |
| **ç©ºäº¡** | ç”³é…‰       | ç”³é…‰       | ç”³é…‰                   | å¯…å¯                |
| **çº³éŸ³** | ç™½èœ¡é‡‘      | åŸå¤´åœŸ      | æ¶§ä¸‹æ°´                  | è¦†ç¯ç«               |
| **ç¥ç…** | å›½å°è´µäºº     | å¤ªæè´µäººã€æœˆå¾·åˆ | é˜´å·®é˜³é”™ã€å¤©ä¹™è´µäººã€å¾·ç§€è´µäººã€å¯¡å®¿ã€æŠ«éº» | å›½å°è´µäººã€æœˆå¾·è´µäººã€å¾·ç§€è´µäººã€åç›– |

ã€æ³¨æ„ã€‘
- ä¸è¦è¾“å‡º markdownã€ç«–çº¿æˆ–åˆ¶è¡¨ç¬¦ï¼›
- ä¸è¦çœç•¥ç©ºåˆ—ï¼›
- ä¸å…è®¸è¾“å‡º"æ— æ³•è¯†åˆ«"æˆ–"ç©º"ï¼›
- ç›´æ¥è¾“å‡ºç¬¦åˆä¸Šè¿°ç»“æ„çš„ JSONã€‚"""
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}"
                            }
                        }
                    ]
                }
            ],
            "temperature": 0.1,
            "max_tokens": 1500
        }
        
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        
        if response.status_code == 200:
            data = response.json()
            # OpenAI-compatible å“åº”æ ¼å¼
            if "choices" in data and len(data["choices"]) > 0:
                choice = data["choices"][0]
                # å°è¯•è·å– message.content
                if "message" in choice and "content" in choice["message"]:
                    return choice["message"]["content"]
                # å°è¯•è·å–ç›´æ¥çš„ text å­—æ®µ
                elif "text" in choice:
                    return choice["text"]
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é¢„æœŸæ ¼å¼ï¼ŒæŠ›å‡ºè¯¦ç»†é”™è¯¯
            raise Exception(f"æ— æ³•è§£æ MiniMax å“åº”æ ¼å¼: {json.dumps(data, ensure_ascii=False)[:200]}")
        
        # è¿”å›è¯¦ç»†é”™è¯¯ä¿¡æ¯
        error_text = response.text[:500] if response.text else "æ— å“åº”å†…å®¹"
        raise Exception(f"MiniMax API è¿”å›é”™è¯¯ {response.status_code}: {error_text}")
    
    def _call_gpt4_vision(self, image_base64: str) -> Optional[str]:
        """è°ƒç”¨ GPT-4 Vision API"""
        
        if not self.openai_client:
            raise Exception("OpenAI client not initialized")
        
        # ç§»é™¤å¯èƒ½çš„ data:image å‰ç¼€
        if "," in image_base64:
            image_base64 = image_base64.split(",", 1)[1]
        
        response = self.openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}"
                            }
                        },
                        {
                            "type": "text",
                            "text": """ä½ æ˜¯ä¸€åä¸“ä¸šçš„å…«å­—å‘½ç›˜è¯†åˆ«ä¸“å®¶ï¼Œæ“…é•¿è¯»å–æ–‡å¢¨å¤©æœºç­‰ç³»ç»Ÿå¯¼å‡ºçš„å‘½ç›˜å›¾ç‰‡ã€‚

ğŸ“¸ è¾“å…¥å†…å®¹ï¼šå…«å­—å‘½ç›˜æˆªå›¾ï¼ˆå«å¹´æŸ±ã€æœˆæŸ±ã€æ—¥æŸ±ã€æ—¶æŸ±åŠå„å±‚ä¿¡æ¯ï¼‰
ğŸ¯ è¾“å‡ºç›®æ ‡ï¼šè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºè¯†åˆ«ç»“æœï¼Œä»¥ JSON ç»“æ„è¡¨ç¤ºè¡¨æ ¼å†…å®¹ã€‚

ã€è¯†åˆ«é‡ç‚¹ã€‘
å¿…é¡»è¯†åˆ«å‡ºä»¥ä¸‹10è¡Œï¼š
ä¸»æ˜Ÿã€å¤©å¹²ã€åœ°æ”¯ã€è—å¹²ã€å‰¯æ˜Ÿã€æ˜Ÿè¿ã€è‡ªåã€ç©ºäº¡ã€çº³éŸ³ã€ç¥ç…ã€‚

ã€è¾“å‡ºJSONæ ¼å¼è¦æ±‚ã€‘
{
  "columns": ["å¹´æŸ±","æœˆæŸ±","æ—¥æŸ±","æ—¶æŸ±"],
  "rows": {
    "ä¸»æ˜Ÿ": ["","","",""],
    "å¤©å¹²": ["","","",""],
    "åœ°æ”¯": ["","","",""],
    "è—å¹²": ["","","",""],
    "å‰¯æ˜Ÿ": ["","","",""],
    "æ˜Ÿè¿": ["","","",""],
    "è‡ªå": ["","","",""],
    "ç©ºäº¡": ["","","",""],
    "çº³éŸ³": ["","","",""],
    "ç¥ç…": ["","","",""]
  }
}

ã€æ ¼å¼è¯´æ˜ã€‘
- æ¯ä¸ªé¡¹ç›®å¯¹åº”å››ä¸ªæŸ±ï¼ˆå¹´ã€æœˆã€æ—¥ã€æ—¶ï¼‰ï¼ŒåŠ¡å¿…ä¿è¯åˆ—æ•°ä¸€è‡´ï¼›
- è‹¥æœ‰å¤šä¸ªé¡¹ç›®ï¼ˆå¦‚è—å¹²ã€å‰¯æ˜Ÿã€ç¥ç…ï¼‰ï¼Œè¯·ç”¨ä¸­æ–‡é¡¿å·"ã€"éš”å¼€ï¼›
- ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ–‡å­—ã€å•ä½æˆ–å¤šä½™å­—æ®µï¼›
- æœ€ç»ˆè¾“å‡ºå¿…é¡»æ˜¯å¯ä»¥è¢« JSON.parse() ç›´æ¥è§£æçš„çº¯JSONã€‚

ã€ç¤ºä¾‹ã€‘
| æ—¥æœŸ     | å¹´æŸ±       | æœˆæŸ±       | æ—¥æŸ±                   | æ—¶æŸ±                |
| :----- | :------- | :------- | :------------------- | :---------------- |
| **ä¸»æ˜Ÿ** | æ­£è´¢       | é£Ÿç¥       | å…ƒç”·                   | æ­£å°                |
| **å¤©å¹²** | åºš        | å·±        | ä¸                    | ç”²                 |
| **åœ°æ”¯** | è¾°        | å¯        | ä¸‘                    | è¾°                 |
| **è—å¹²** | æˆŠåœŸã€ä¹™æœ¨ã€ç™¸æ°´ | ä¹™æœ¨       | å·±åœŸã€ç™¸æ°´ã€è¾›é‡‘             | æˆŠåœŸã€ä¹™æœ¨ã€ç™¸æ°´          |
| **å‰¯æ˜Ÿ** | ä¼¤å®˜ã€åå°ã€ä¸ƒæ€ | åå°       | é£Ÿç¥ã€ä¸ƒæ€ã€åè´¢             | ä¼¤å®˜ã€åå°ã€ä¸ƒæ€          |
| **æ˜Ÿè¿** | è¡°        | ç—…        | å¢“                    | è¡°                 |
| **è‡ªå** | å…»        | ç—…        | å¢“                    | è¡°                 |
| **ç©ºäº¡** | ç”³é…‰       | ç”³é…‰       | ç”³é…‰                   | å¯…å¯                |
| **çº³éŸ³** | ç™½èœ¡é‡‘      | åŸå¤´åœŸ      | æ¶§ä¸‹æ°´                  | è¦†ç¯ç«               |
| **ç¥ç…** | å›½å°è´µäºº     | å¤ªæè´µäººã€æœˆå¾·åˆ | é˜´å·®é˜³é”™ã€å¤©ä¹™è´µäººã€å¾·ç§€è´µäººã€å¯¡å®¿ã€æŠ«éº» | å›½å°è´µäººã€æœˆå¾·è´µäººã€å¾·ç§€è´µäººã€åç›– |

ã€æ³¨æ„ã€‘
- ä¸è¦è¾“å‡º markdownã€ç«–çº¿æˆ–åˆ¶è¡¨ç¬¦ï¼›
- ä¸è¦çœç•¥ç©ºåˆ—ï¼›
- ä¸å…è®¸è¾“å‡º"æ— æ³•è¯†åˆ«"æˆ–"ç©º"ï¼›
- ç›´æ¥è¾“å‡ºç¬¦åˆä¸Šè¿°ç»“æ„çš„ JSONã€‚"""
                        }
                    ]
                }
            ],
            temperature=0.1,
            max_tokens=1500
        )
        
        return response.choices[0].message.content
    
    def _get_simulated_data(self) -> str:
        """è¿”å›æ¨¡æ‹Ÿå…«å­—æ•°æ®ï¼ˆæ–° JSON æ ¼å¼ï¼‰"""
        return """{
  "columns": ["å¹´æŸ±","æœˆæŸ±","æ—¥æŸ±","æ—¶æŸ±"],
  "rows": {
    "ä¸»æ˜Ÿ": ["æ­£è´¢","é£Ÿç¥","å…ƒç”·","æ­£å°"],
    "å¤©å¹²": ["åºš","å·±","ä¸","ç”²"],
    "åœ°æ”¯": ["è¾°","å¯","ä¸‘","è¾°"],
    "è—å¹²": ["æˆŠåœŸã€ä¹™æœ¨ã€ç™¸æ°´","ä¹™æœ¨","å·±åœŸã€ç™¸æ°´ã€è¾›é‡‘","æˆŠåœŸã€ä¹™æœ¨ã€ç™¸æ°´"],
    "å‰¯æ˜Ÿ": ["ä¼¤å®˜ã€åå°ã€ä¸ƒæ€","åå°","é£Ÿç¥ã€ä¸ƒæ€ã€åè´¢","ä¼¤å®˜ã€åå°ã€ä¸ƒæ€"],
    "æ˜Ÿè¿": ["è¡°","ç—…","å¢“","è¡°"],
    "è‡ªå": ["å…»","ç—…","å¢“","è¡°"],
    "ç©ºäº¡": ["ç”³é…‰","ç”³é…‰","ç”³é…‰","å¯…å¯"],
    "çº³éŸ³": ["ç™½èœ¡é‡‘","åŸå¤´åœŸ","æ¶§ä¸‹æ°´","è¦†ç¯ç«"],
    "ç¥ç…": ["å›½å°è´µäºº","å¤ªæè´µäººã€æœˆå¾·åˆ","é˜´å·®é˜³é”™ã€å¤©ä¹™è´µäººã€å¾·ç§€è´µäººã€å¯¡å®¿ã€æŠ«éº»","å›½å°è´µäººã€æœˆå¾·è´µäººã€å¾·ç§€è´µäººã€åç›–"]
  }
}"""
    
    def _normalizer_layer(self, raw_text: str, progress_callback=None) -> Dict:
        """Layer 2: Normalizer Agent - æ ‡å‡†åŒ–æ•°æ®ï¼ˆæ”¯æŒæ–° JSON æ ¼å¼ï¼‰"""
        
        if progress_callback:
            progress_callback("ğŸ”§ æ ‡å‡†åŒ–å››æŸ±æ•°æ®...")
        
        result = {
            "year_gan": "", "year_zhi": "",
            "month_gan": "", "month_zhi": "",
            "day_gan": "", "day_zhi": "",
            "hour_gan": "", "hour_zhi": "",
            "gender": "",
            "birth_time": "",
            "full_table": None  # å­˜å‚¨å®Œæ•´çš„ 10 è¡Œæ•°æ®
        }
        
        # å°è¯•è§£æ JSON æ ¼å¼ï¼ˆæ–°æ ¼å¼ï¼‰
        try:
            # æå– JSON éƒ¨åˆ†ï¼ˆå¯èƒ½åŒ…å«é¢å¤–æ–‡æœ¬ï¼‰
            json_start = raw_text.find("{")
            json_end = raw_text.rfind("}") + 1
            
            if json_start >= 0 and json_end > json_start:
                json_text = raw_text[json_start:json_end]
                data = json.loads(json_text)
                
                if "rows" in data and "å¤©å¹²" in data["rows"] and "åœ°æ”¯" in data["rows"]:
                    # è§£æå¤©å¹²åœ°æ”¯
                    tiangan = data["rows"]["å¤©å¹²"]
                    dizhi = data["rows"]["åœ°æ”¯"]
                    
                    if len(tiangan) >= 4 and len(dizhi) >= 4:
                        result["year_gan"] = tiangan[0]
                        result["month_gan"] = tiangan[1]
                        result["day_gan"] = tiangan[2]
                        result["hour_gan"] = tiangan[3]
                        
                        result["year_zhi"] = dizhi[0]
                        result["month_zhi"] = dizhi[1]
                        result["day_zhi"] = dizhi[2]
                        result["hour_zhi"] = dizhi[3]
                        
                        # å­˜å‚¨å®Œæ•´è¡¨æ ¼æ•°æ®
                        result["full_table"] = data
                        
                        if progress_callback:
                            progress_callback(f"âœ… è¯†åˆ«åˆ°å®Œæ•´å‘½ç›˜: {result['year_gan']}{result['year_zhi']} {result['month_gan']}{result['month_zhi']} {result['day_gan']}{result['day_zhi']} {result['hour_gan']}{result['hour_zhi']}")
                        
                        return result
        
        except (json.JSONDecodeError, KeyError, IndexError) as e:
            if progress_callback:
                progress_callback(f"âš ï¸ JSON è§£æå¤±è´¥ï¼Œå°è¯•æ—§æ ¼å¼è§£æ...")
        
        # å¦‚æœ JSON è§£æå¤±è´¥ï¼Œå›é€€åˆ°æ—§æ ¼å¼è§£æï¼ˆå‘åå…¼å®¹ï¼‰
        lines = raw_text.strip().split("\n")
        
        for line in lines:
            line = line.strip()
            
            if "å¹´æŸ±" in line or "Year" in line:
                chars = self._extract_ganzhi(line)
                if len(chars) >= 2:
                    result["year_gan"], result["year_zhi"] = chars[0], chars[1]
            
            elif "æœˆæŸ±" in line or "Month" in line:
                chars = self._extract_ganzhi(line)
                if len(chars) >= 2:
                    result["month_gan"], result["month_zhi"] = chars[0], chars[1]
            
            elif "æ—¥æŸ±" in line or "Day" in line:
                chars = self._extract_ganzhi(line)
                if len(chars) >= 2:
                    result["day_gan"], result["day_zhi"] = chars[0], chars[1]
            
            elif "æ—¶æŸ±" in line or "Hour" in line:
                chars = self._extract_ganzhi(line)
                if len(chars) >= 2:
                    result["hour_gan"], result["hour_zhi"] = chars[0], chars[1]
            
            elif "æ€§åˆ«" in line or "Gender" in line:
                if "ç”·" in line or "Male" in line:
                    result["gender"] = "ç”·"
                elif "å¥³" in line or "Female" in line:
                    result["gender"] = "å¥³"
            
            elif "å‡ºç”Ÿæ—¶é—´" in line or "Birth" in line:
                parts = line.split(":", 1)
                if len(parts) > 1:
                    result["birth_time"] = parts[1].strip()
        
        if progress_callback:
            progress_callback(f"âœ… è¯†åˆ«åˆ°: {result['year_gan']}{result['year_zhi']} {result['month_gan']}{result['month_zhi']} {result['day_gan']}{result['day_zhi']} {result['hour_gan']}{result['hour_zhi']}")
        
        return result
    
    def _extract_ganzhi(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–å¹²æ”¯å­—ç¬¦"""
        chars = []
        all_chars = self.tiangan + self.dizhi
        
        for char in text:
            if char in all_chars:
                chars.append(char)
        
        return chars
    
    def _formatter_layer(self, normalized_data: Dict, progress_callback=None) -> Dict:
        """Layer 3: Formatter Agent - æ ¼å¼åŒ–è¾“å‡ºï¼ˆåŒ…å«å®Œæ•´ 10 è¡Œæ•°æ®ï¼‰"""
        
        if progress_callback:
            progress_callback("ğŸ“¦ æ ¼å¼åŒ–è¾“å‡ºæ•°æ®...")
        
        # è®¡ç®—äº”è¡Œ
        wuxing = self._calculate_wuxing(normalized_data)
        
        result = {
            "bazi": {
                "year": f"{normalized_data['year_gan']}{normalized_data['year_zhi']}",
                "month": f"{normalized_data['month_gan']}{normalized_data['month_zhi']}",
                "day": f"{normalized_data['day_gan']}{normalized_data['day_zhi']}",
                "hour": f"{normalized_data['hour_gan']}{normalized_data['hour_zhi']}"
            },
            "pillars": {
                "year_gan": normalized_data["year_gan"],
                "year_zhi": normalized_data["year_zhi"],
                "month_gan": normalized_data["month_gan"],
                "month_zhi": normalized_data["month_zhi"],
                "day_gan": normalized_data["day_gan"],
                "day_zhi": normalized_data["day_zhi"],
                "hour_gan": normalized_data["hour_gan"],
                "hour_zhi": normalized_data["hour_zhi"]
            },
            "gender": normalized_data.get("gender", ""),
            "birth_time": normalized_data.get("birth_time", ""),
            "wuxing": wuxing
        }
        
        # å¦‚æœæœ‰å®Œæ•´è¡¨æ ¼æ•°æ®ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
        if normalized_data.get("full_table"):
            result["full_table"] = normalized_data["full_table"]
            if progress_callback:
                progress_callback("âœ… å·²åŒ…å«å®Œæ•´ 10 è¡Œå‘½ç›˜æ•°æ®")
        
        return result
    
    def _calculate_wuxing(self, data: Dict) -> Dict:
        """è®¡ç®—äº”è¡Œåˆ†å¸ƒ"""
        wuxing_count = {"é‡‘": 0, "æœ¨": 0, "æ°´": 0, "ç«": 0, "åœŸ": 0}
        
        chars = [
            data["year_gan"], data["year_zhi"],
            data["month_gan"], data["month_zhi"],
            data["day_gan"], data["day_zhi"],
            data["hour_gan"], data["hour_zhi"]
        ]
        
        for char in chars:
            if char in self.wuxing_map:
                wuxing = self.wuxing_map[char]
                wuxing_count[wuxing] += 1
        
        return wuxing_count


# ä¾¿æ·å‡½æ•°
def process_bazi_image(image_base64: str, progress_callback=None) -> Dict:
    """
    å¤„ç†å…«å­—å›¾ç‰‡çš„ä¾¿æ·å‡½æ•°
    
    Args:
        image_base64: Base64 ç¼–ç çš„å›¾ç‰‡æ•°æ®
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
    
    Returns:
        è¯†åˆ«ç»“æœå­—å…¸
    """
    agent = BaziVisionAgent()
    return agent.process_image(image_base64, progress_callback)
